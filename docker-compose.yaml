services:
  # ======================
  # Airflow + Postgres
  # ======================
  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PW}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - slo_ex_postgres_data:/var/lib/postgresql/data

  airflow:
    image: apache/airflow:3.1.0
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY}
      AIRFLOW__CORE__SIMPLE_AUTH_MANAGER_ALL_ADMINS: "True"
      AIRFLOW__CORE__SIMPLE_AUTH_MANAGER_USERS: "${AIRFLOW_USER}:${AIRFLOW_PW}" # use comma for more users
      AIRFLOW__API__PORT: ${AIRFLOW_WEBSERVER_PORT}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_SQL_ALCHEMY_CONN}

    ports:
      - "8080:8080"
    volumes:
      - ./airflow:/opt/airflow
    command: >
      bash -lc "airflow db migrate &&
        (airflow api-server --port 8080 &) &&
        (airflow scheduler &) &&
        (airflow dag-processor &) &&
        (airflow triggerer &) &&
        tail -f /dev/null
      "

  # ======================
  # Kafka Stack
  # ======================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.10
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    volumes:
      - slo_ex_zk_data:/var/lib/zookeeper/data
      - slo_ex_zk_log:/var/lib/zookeeper/log

  kafka:
    image: confluentinc/cp-kafka:7.4.10
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:29092,EXTERNAL://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_BYTES: 85899345920 # 80 GB per partition
      # KAFKA_LOG_RETENTION_MS: -1               # disable time-based retention
      KAFKA_LOG_CLEANUP_POLICY: delete
    ports:
      - "9092:9092"
    volumes:
      - slo_ex_kafka_data:/var/lib/kafka/data # persistence, need retention policy

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    depends_on:
      - kafka
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    ports:
      - "8085:8080"

  # ======================
  # Spark Cluster
  # ======================
  spark-master:
    image: apache/spark:latest
    container_name: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --host spark-master
    ports:
      - "7077:7077"
      - "8081:8080"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
    volumes:
      - slo_ex_spark_checkpoints:/checkpoints # for Spark Structured Streaming

  spark-worker-1:
    image: apache/spark:latest
    container_name: spark-worker-1
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_MODE=worker
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=4G
    volumes:
      - slo_ex_spark_checkpoints:/checkpoints

  spark-worker-2:
    image: apache/spark:latest
    container_name: spark-worker-2
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_MODE=worker
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=4G
    volumes:
      - slo_ex_spark_checkpoints:/checkpoints

  # ======================
  # ClickHouse
  # ======================
  clickhouse:
    image: clickhouse:latest
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - slo_ex_clickhouse_data:/var/lib/clickhouse

  # ======================
  # Grafana
  # ======================
  grafana:
    image: grafana/grafana:latest
    depends_on:
      # - clickhouse
      - prometheus
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GF_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GF_PW}
    volumes:
      - slo_ex_grafana_data:/var/lib/grafana

  # ======================
  # Prometheus
  # ======================
  prometheus:
    image: prom/prometheus:v2.55.0
    volumes:
      - ./prometheus/prometheus.yaml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/alerts.yaml:/etc/prometheus/alerts.yml:ro
    ports:
      - "9090:9090"

  # ======================
  # Fakers Prod / Cons
  # ======================
  producer:
    build:
      context: ./faker
      dockerfile: prod.Dockerfile
    image: xuanminator/slo-test-prod
    ports:
      - "8000:8000"
    environment:
      - BROKERS=${BROKERS}
      - TOPIC=${TOPIC}
      - RATE=${RATE}
      - PAYLOAD=${PAYLOAD}
      - PROD_METRICS_PORT=${PROD_METRICS_PORT}
    depends_on:
      - prometheus
      - kafka
  consumer:
    build:
      context: ./faker
      dockerfile: cons.Dockerfile
    image: xuanminator/slo-test-cons
    ports:
      - "8001:8001"
    depends_on:
      - producer
      - kafka
    environment:
      - BROKERS=${BROKERS}
      - TOPIC=${TOPIC}
      - CONS_METRICS_PORT=${CONS_METRICS_PORT}
      - GROUP=${GROUP}

# ======================
# Volumes
# ======================
volumes:
  slo_ex_postgres_data:
  slo_ex_clickhouse_data:
  slo_ex_grafana_data:
  slo_ex_kafka_data:
  slo_ex_zk_data:
  slo_ex_zk_log:
  slo_ex_spark_checkpoints:
